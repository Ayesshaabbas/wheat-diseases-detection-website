{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåæ Wheat Disease Detection - Complete Training Pipeline\n",
    "This notebook will train a robust model that can accurately distinguish between different wheat diseases, especially Yellow Rust vs Brown Rust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install tensorflow matplotlib seaborn scikit-learn opencv-python pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Data Setup and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths - ADJUST THESE TO YOUR DATA STRUCTURE\n",
    "TRAIN_DIR = 'train'  # Change this to your training data path\n",
    "VAL_DIR = 'val'      # Change this to your validation data path\n",
    "TEST_DIR = 'test'    # Change this to your test data path (if available)\n",
    "\n",
    "# Image parameters\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "\n",
    "# Check if directories exist\n",
    "for directory in [TRAIN_DIR, VAL_DIR]:\n",
    "    if os.path.exists(directory):\n",
    "        print(f\"‚úÖ Found: {directory}\")\n",
    "        classes = os.listdir(directory)\n",
    "        print(f\"   Classes: {classes}\")\n",
    "        for cls in classes:\n",
    "            cls_path = os.path.join(directory, cls)\n",
    "            if os.path.isdir(cls_path):\n",
    "                count = len([f for f in os.listdir(cls_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "                print(f\"   {cls}: {count} images\")\n",
    "    else:\n",
    "        print(f\"‚ùå Not found: {directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators with robust augmentation\n",
    "def create_data_generators():\n",
    "    \"\"\"Create data generators with proper augmentation\"\"\"\n",
    "    \n",
    "    # Training data generator with augmentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Validation data generator (no augmentation, only rescaling)\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # Create generators\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        TRAIN_DIR,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        VAL_DIR,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator\n",
    "\n",
    "# Create generators\n",
    "train_gen, val_gen = create_data_generators()\n",
    "\n",
    "# Get class information\n",
    "class_names = list(train_gen.class_indices.keys())\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"\\nüìä Dataset Information:\")\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Training samples: {train_gen.samples}\")\n",
    "print(f\"Validation samples: {val_gen.samples}\")\n",
    "print(f\"Training steps per epoch: {len(train_gen)}\")\n",
    "print(f\"Validation steps per epoch: {len(val_gen)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights for imbalanced data\n",
    "def calculate_class_weights(generator):\n",
    "    \"\"\"Calculate class weights to handle imbalanced datasets\"\"\"\n",
    "    \n",
    "    # Get all labels\n",
    "    labels = generator.labels\n",
    "    \n",
    "    # Calculate class weights\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(labels),\n",
    "        y=labels\n",
    "    )\n",
    "    \n",
    "    class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "    \n",
    "    # Display class distribution\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    \n",
    "    print(\"\\nüìä Class Distribution:\")\n",
    "    for i, (class_idx, count) in enumerate(zip(unique, counts)):\n",
    "        class_name = class_names[class_idx]\n",
    "        weight = class_weights[i]\n",
    "        percentage = (count / len(labels)) * 100\n",
    "        print(f\"  {class_name}: {count} samples ({percentage:.1f}%) - Weight: {weight:.2f}\")\n",
    "    \n",
    "    return class_weight_dict\n",
    "\n",
    "class_weights = calculate_class_weights(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from each class\n",
    "def visualize_samples():\n",
    "    \"\"\"Visualize sample images from each class\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(len(class_names), 5, figsize=(15, len(class_names) * 3))\n",
    "    fig.suptitle('Sample Images from Each Class', fontsize=16)\n",
    "    \n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(TRAIN_DIR, class_name)\n",
    "        \n",
    "        if os.path.exists(class_dir):\n",
    "            image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:5]\n",
    "            \n",
    "            for img_idx, img_file in enumerate(image_files):\n",
    "                if img_idx >= 5:\n",
    "                    break\n",
    "                    \n",
    "                img_path = os.path.join(class_dir, img_file)\n",
    "                \n",
    "                try:\n",
    "                    img = Image.open(img_path)\n",
    "                    if img.mode != 'RGB':\n",
    "                        img = img.convert('RGB')\n",
    "                    \n",
    "                    if len(class_names) == 1:\n",
    "                        ax = axes[img_idx]\n",
    "                    else:\n",
    "                        ax = axes[class_idx, img_idx]\n",
    "                    \n",
    "                    ax.imshow(img)\n",
    "                    ax.set_title(f'{class_name}\\n{img_file[:15]}...', fontsize=8)\n",
    "                    ax.axis('off')\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    if len(class_names) == 1:\n",
    "                        ax = axes[img_idx]\n",
    "                    else:\n",
    "                        ax = axes[class_idx, img_idx]\n",
    "                    ax.text(0.5, 0.5, f'Error loading\\n{img_file}', \n",
    "                           ha='center', va='center', transform=ax.transAxes)\n",
    "                    ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_enhanced_model(num_classes):\n",
    "    \"\"\"Create an enhanced CNN model for wheat disease classification\"\"\"\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        # Input layer\n",
    "        layers.Input(shape=(*IMG_SIZE, 3)),\n",
    "        \n",
    "        # First convolutional block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Second convolutional block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Third convolutional block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Fourth convolutional block\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Fifth convolutional block\n",
    "        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        \n",
    "        # Dense layers\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Output layer\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_enhanced_model(num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', 'top_2_accuracy']\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "print(\"üèóÔ∏è Model Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# Calculate total parameters\n",
    "total_params = model.count_params()\n",
    "print(f\"\\nüìä Total parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "def create_callbacks():\n",
    "    \"\"\"Create training callbacks\"\"\"\n",
    "    \n",
    "    callback_list = [\n",
    "        # Early stopping\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Reduce learning rate on plateau\n",
    "        callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=7,\n",
    "            min_lr=1e-8,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Model checkpoint\n",
    "        callbacks.ModelCheckpoint(\n",
    "            'best_wheat_model.keras',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # CSV logger\n",
    "        callbacks.CSVLogger('training_log.csv')\n",
    "    ]\n",
    "    \n",
    "    return callback_list\n",
    "\n",
    "model_callbacks = create_callbacks()\n",
    "print(\"‚úÖ Callbacks created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"üöÄ Starting model training...\")\n",
    "print(f\"Training for up to {EPOCHS} epochs with early stopping\")\n",
    "print(\"This may take a while depending on your hardware...\\n\")\n",
    "\n",
    "# Start training\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=len(val_gen),\n",
    "    callbacks=model_callbacks,\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Training Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Training History', fontsize=16)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 0].plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
    "    axes[0, 0].plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
    "    axes[0, 0].set_title('Model Accuracy')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 1].plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "    axes[0, 1].plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
    "    axes[0, 1].set_title('Model Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Top-2 Accuracy\n",
    "    if 'top_2_accuracy' in history.history:\n",
    "        axes[1, 0].plot(history.history['top_2_accuracy'], label='Training Top-2 Acc', color='blue')\n",
    "        axes[1, 0].plot(history.history['val_top_2_accuracy'], label='Validation Top-2 Acc', color='red')\n",
    "        axes[1, 0].set_title('Top-2 Accuracy')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Top-2 Accuracy')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True)\n",
    "    \n",
    "    # Learning Rate\n",
    "    if 'lr' in history.history:\n",
    "        axes[1, 1].plot(history.history['lr'], label='Learning Rate', color='green')\n",
    "        axes[1, 1].set_title('Learning Rate')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Learning Rate')\n",
    "        axes[1, 1].set_yscale('log')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True)\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, 'Learning Rate\\nNot Recorded', \n",
    "                        ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "        axes[1, 1].set_title('Learning Rate')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"üìä Model Evaluation:\")\n",
    "\n",
    "# Training evaluation\n",
    "train_loss, train_acc, train_top2 = model.evaluate(train_gen, verbose=0)\n",
    "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Training Top-2 Accuracy: {train_top2:.4f}\")\n",
    "print(f\"Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "# Validation evaluation\n",
    "val_loss, val_acc, val_top2 = model.evaluate(val_gen, verbose=0)\n",
    "print(f\"\\nValidation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"Validation Top-2 Accuracy: {val_top2:.4f}\")\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Check for overfitting\n",
    "overfitting_score = train_acc - val_acc\n",
    "print(f\"\\nOverfitting Score: {overfitting_score:.4f}\")\n",
    "if overfitting_score > 0.1:\n",
    "    print(\"‚ö†Ô∏è Model might be overfitting (training acc >> validation acc)\")\n",
    "elif overfitting_score < 0.05:\n",
    "    print(\"‚úÖ Good generalization (low overfitting)\")\n",
    "else:\n",
    "    print(\"üîÑ Moderate overfitting (acceptable)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Detailed Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for confusion matrix\n",
    "def generate_predictions():\n",
    "    \"\"\"Generate predictions for detailed analysis\"\"\"\n",
    "    \n",
    "    print(\"üîÆ Generating predictions for analysis...\")\n",
    "    \n",
    "    # Reset validation generator\n",
    "    val_gen.reset()\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = model.predict(val_gen, steps=len(val_gen), verbose=1)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Get true labels\n",
    "    true_classes = val_gen.classes\n",
    "    \n",
    "    return predictions, predicted_classes, true_classes\n",
    "\n",
    "predictions, predicted_classes, true_classes = generate_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "def plot_confusion_matrix(true_classes, predicted_classes, class_names):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    \n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix', fontsize=16)\n",
    "    plt.xlabel('Predicted Class', fontsize=12)\n",
    "    plt.ylabel('True Class', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return cm\n",
    "\n",
    "cm = plot_confusion_matrix(true_classes, predicted_classes, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"üìã Detailed Classification Report:\")\n",
    "print(\"=\" * 50)\n",
    "report = classification_report(true_classes, predicted_classes, \n",
    "                             target_names=class_names, digits=4)\n",
    "print(report)\n",
    "\n",
    "# Save classification report\n",
    "with open('classification_report.txt', 'w') as f:\n",
    "    f.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze specific class performance (especially rust classes)\n",
    "def analyze_rust_performance():\n",
    "    \"\"\"Analyze performance specifically for rust classes\"\"\"\n",
    "    \n",
    "    print(\"ü¶† Rust Classes Analysis:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    rust_classes = ['Yellow Rust', 'brown rust']\n",
    "    \n",
    "    for rust_class in rust_classes:\n",
    "        if rust_class in class_names:\n",
    "            class_idx = class_names.index(rust_class)\n",
    "            \n",
    "            # Get indices where true class is this rust type\n",
    "            true_rust_indices = np.where(true_classes == class_idx)[0]\n",
    "            \n",
    "            if len(true_rust_indices) > 0:\n",
    "                # Get predictions for these samples\n",
    "                rust_predictions = predicted_classes[true_rust_indices]\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                correct = np.sum(rust_predictions == class_idx)\n",
    "                total = len(true_rust_indices)\n",
    "                accuracy = (correct / total) * 100\n",
    "                \n",
    "                print(f\"\\n{rust_class}:\")\n",
    "                print(f\"  Accuracy: {correct}/{total} ({accuracy:.1f}%)\")\n",
    "                \n",
    "                # Show what it's confused with\n",
    "                unique_preds, counts = np.unique(rust_predictions, return_counts=True)\n",
    "                print(\"  Predicted as:\")\n",
    "                for pred_idx, count in zip(unique_preds, counts):\n",
    "                    pred_class = class_names[pred_idx]\n",
    "                    percentage = (count / total) * 100\n",
    "                    print(f\"    {pred_class}: {count}/{total} ({percentage:.1f}%)\")\n",
    "                \n",
    "                # Show confidence scores for misclassified samples\n",
    "                misclassified = true_rust_indices[rust_predictions != class_idx]\n",
    "                if len(misclassified) > 0:\n",
    "                    print(f\"  \\n  Misclassified samples confidence:\")\n",
    "                    for i, sample_idx in enumerate(misclassified[:3]):  # Show first 3\n",
    "                        pred_probs = predictions[sample_idx]\n",
    "                        true_conf = pred_probs[class_idx] * 100\n",
    "                        pred_conf = np.max(pred_probs) * 100\n",
    "                        pred_class = class_names[np.argmax(pred_probs)]\n",
    "                        print(f\"    Sample {i+1}: True class confidence: {true_conf:.1f}%, Predicted: {pred_class} ({pred_conf:.1f}%)\")\n",
    "\n",
    "analyze_rust_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Model Saving and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "model.save('trained_model.keras')\n",
    "print(\"üíæ Model saved as 'trained_model.keras'\")\n",
    "\n",
    "# Save training history\n",
    "history_dict = {}\n",
    "for key, values in history.history.items():\n",
    "    history_dict[key] = [float(v) for v in values]\n",
    "\n",
    "with open('training_history.json', 'w') as f:\n",
    "    json.dump(history_dict, f, indent=2)\n",
    "\n",
    "print(\"üíæ Training history saved as 'training_history.json'\")\n",
    "\n",
    "# Save class names\n",
    "with open('class_names.json', 'w') as f:\n",
    "    json.dump(class_names, f, indent=2)\n",
    "\n",
    "print(\"üíæ Class names saved as 'class_names.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with sample predictions\n",
    "def test_sample_predictions(num_samples=5):\n",
    "    \"\"\"Test the model with sample predictions\"\"\"\n",
    "    \n",
    "    print(f\"üß™ Testing model with {num_samples} sample predictions:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Reset generator\n",
    "    val_gen.reset()\n",
    "    \n",
    "    # Get a batch\n",
    "    batch_images, batch_labels = next(val_gen)\n",
    "    \n",
    "    for i in range(min(num_samples, len(batch_images))):\n",
    "        # Get single image\n",
    "        image = batch_images[i:i+1]\n",
    "        true_label = np.argmax(batch_labels[i])\n",
    "        true_class = class_names[true_label]\n",
    "        \n",
    "        # Predict\n",
    "        prediction = model.predict(image, verbose=0)\n",
    "        predicted_label = np.argmax(prediction[0])\n",
    "        predicted_class = class_names[predicted_label]\n",
    "        confidence = np.max(prediction[0]) * 100\n",
    "        \n",
    "        # Show results\n",
    "        status = \"‚úÖ\" if predicted_class == true_class else \"‚ùå\"\n",
    "        print(f\"\\nSample {i+1}: {status}\")\n",
    "        print(f\"  True class: {true_class}\")\n",
    "        print(f\"  Predicted: {predicted_class} ({confidence:.1f}% confidence)\")\n",
    "        \n",
    "        # Show all class probabilities\n",
    "        print(\"  All predictions:\")\n",
    "        for j, class_name in enumerate(class_names):\n",
    "            prob = prediction[0][j] * 100\n",
    "            print(f\"    {class_name}: {prob:.1f}%\")\n",
    "\n",
    "test_sample_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Final Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"üéâ TRAINING COMPLETE!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìä Final Results:\")\n",
    "print(f\"   Validation Accuracy: {val_acc:.1%}\")\n",
    "print(f\"   Validation Top-2 Accuracy: {val_top2:.1%}\")\n",
    "print(f\"   Total Training Epochs: {len(history.history['accuracy'])}\")\n",
    "\n",
    "print(f\"\\nüìÅ Files Created:\")\n",
    "files_created = [\n",
    "    'trained_model.keras',\n",
    "    'best_wheat_model.keras',\n",
    "    'training_history.json',\n",
    "    'class_names.json',\n",
    "    'training_log.csv',\n",
    "    'classification_report.txt',\n",
    "    'training_history.png',\n",
    "    'confusion_matrix.png'\n",
    "]\n",
    "\n",
    "for file in files_created:\n",
    "    if os.path.exists(file):\n",
    "        print(f\"   ‚úÖ {file}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {file} (not created)\")\n",
    "\n",
    "print(f\"\\nüöÄ Next Steps:\")\n",
    "print(\"1. Copy 'trained_model.keras' to your Flask backend directory\")\n",
    "print(\"2. Update your backend class_names to match the training order\")\n",
    "print(\"3. Restart your Flask backend server\")\n",
    "print(\"4. Test with your web interface\")\n",
    "\n",
    "if val_acc < 0.8:\n",
    "    print(f\"\\n‚ö†Ô∏è Recommendations for Improvement:\")\n",
    "    print(\"   - Collect more training data, especially for poorly performing classes\")\n",
    "    print(\"   - Ensure data quality and correct labeling\")\n",
    "    print(\"   - Try different augmentation strategies\")\n",
    "    print(\"   - Consider transfer learning with pre-trained models\")\n",
    "elif val_acc > 0.9:\n",
    "    print(f\"\\nüéâ Excellent Results!\")\n",
    "    print(\"   Your model should work very well for wheat disease detection!\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Good Results!\")\n",
    "    print(\"   Your model should work well for most cases.\")\n",
    "\n",
    "print(f\"\\nüìã Class Names (in order):\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"   {i}: {class_name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üåæ Happy wheat disease detection! üåæ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
